{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST & CIFAR DATA EXPLORATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maia Rosengarten <br/>\n",
    "June 1, 2016 <br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BACKGROUND\n",
    "<h3> *** FILL IN ***** </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> Data Sets </strong>\n",
    "<ol>\n",
    "    <li><u> MNIST</u>: FILL IN </li>\n",
    "    <li><u> CIFAR-10</u>: FILL IN </li>\n",
    "    <li><u> SPAM</u>: FILL IN </li>\n",
    "</ol>\n",
    "<strong> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import io\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 1: LOADING AND SPLITTING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -----------MNIST SET-------- (sklearn fn)\n",
    "mnist_dict = io.loadmat('mnist/train.mat')\n",
    "mnist_trainX = mnist_dict['trainX']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> SPLITTING DATA INTO TRAIN, TEST, and VALIDATION SETS</strong><br/>\n",
    "<em> Using sklearn.model's built in train_test_split method </em> <br/>\n",
    "Check it out [INSERT LINK] -- very useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLITTING MNIST DATA INTO TRAIN AND VALID SAMPLES & LABELS:\n",
      "________________________________________________________\n",
      "PRINTING SHAPES (rows, columns):\n",
      "mnist_train_set (50000, 784)\n",
      "mnist_valid_set (10000, 784)\n",
      "mnist_train_y (50000,)\n",
      "mnist_valid_y (10000,)\n"
     ]
    }
   ],
   "source": [
    "mnist_train_set, mnist_valid_set, mnist_train_y, mnist_valid_y = train_test_split(mnist_trainX[:, :-1], mnist_trainX[:, -1], test_size=10000, random_state=42)\n",
    "print('SPLITTING MNIST DATA INTO TRAIN AND VALID SAMPLES & LABELS:')\n",
    "print('________________________________________________________')\n",
    "print(\"PRINTING SHAPES (rows, columns):\")\n",
    "print('mnist_train_set ' + str(mnist_train_set.shape))\n",
    "print('mnist_valid_set ' + str(mnist_valid_set.shape))\n",
    "print('mnist_train_y ' + str(mnist_train_y.shape))\n",
    "print('mnist_valid_y ' + str(mnist_valid_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -----------CIFAR-10 SET -------- (sklearn fn)\n",
    "cifar_dict = sp.io.loadmat('cifar/train.mat')\n",
    "cifar_trainX = cifar_dict['trainX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cifar_train_set, cifar_valid_set, cifar_train_y, cifar_valid_y = train_test_split(cifar_trainX[:, :-1], cifar_trainX[:, -1], test_size=5000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLITTING CIFAR DATA INTO TRAIN AND VALID SAMPLES & LABELS:\n",
      "________________________________________________________\n",
      "PRINTING SHAPES (rows, columns):\n",
      "cifar_train_set (45000, 3072)\n",
      "cifar_valid_set (5000, 3072)\n",
      "cifar_train_y (45000,)\n",
      "cifar_valid_y (5000,)\n"
     ]
    }
   ],
   "source": [
    "print('SPLITTING CIFAR DATA INTO TRAIN AND VALID SAMPLES & LABELS:')\n",
    "print('________________________________________________________')\n",
    "print(\"PRINTING SHAPES (rows, columns):\")\n",
    "print('cifar_train_set ' + str(cifar_train_set.shape))\n",
    "print('cifar_valid_set ' + str(cifar_valid_set.shape))\n",
    "print('cifar_train_y ' + str(cifar_train_y.shape))\n",
    "print('cifar_valid_y ' + str(cifar_valid_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# --------------SPAM DataSet (sklearn fn)----------------\n",
    "spam_dict = sp.io.loadmat('spam/spam_data.mat')\n",
    "spam_trainX= spam_dict['training_data']\n",
    "spam_labels = spam_dict['training_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spam_train_set, spam_valid_set, spam_train_y, spam_valid_y = train_test_split(spam_trainX, spam_labels.T, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLITTING SPAM DATA INTO TRAIN AND VALID SAMPLES & LABELS:\n",
      "________________________________________________________\n",
      "PRINTING SHAPES (rows, columns):\n",
      "spam_train_set (4137, 32)\n",
      "spam_valid_set (1035, 32)\n",
      "spam_train_y (4137, 1)\n",
      "spam_valid_y (1035, 1)\n"
     ]
    }
   ],
   "source": [
    "print('SPLITTING SPAM DATA INTO TRAIN AND VALID SAMPLES & LABELS:')\n",
    "print('________________________________________________________')\n",
    "print(\"PRINTING SHAPES (rows, columns):\")\n",
    "print('spam_train_set ' + str(spam_train_set.shape))\n",
    "print('spam_valid_set ' + str(spam_valid_set.shape))\n",
    "print('spam_train_y ' + str(spam_train_y.shape))\n",
    "print('spam_valid_y ' + str(spam_valid_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 2: TRAINING SVM CLASSIFIERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>A. I wrote three functions to train our data using SVM classifier and plot the training and validation accuracies</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plots accuracy, returns None\n",
    "def plot_accuracy(x, y, name):\n",
    "    plt.plot(x, y)\n",
    "    plt.xlabel('num_samples')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.title(name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_svm(samples, clf, train_set, train_y, valid_set, valid_y, name):\n",
    "    valid_error, train_error = train_svm_no_plot(samples, clf, train_set, train_y, valid_set, valid_y, name)\n",
    "    plot_accuracy(samples, train_error, name + ' Training_Accuracy')\n",
    "    plot_accuracy(samples, valid_error, name + ' Validation_Accuracy')\n",
    "    return valid_error, train_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Purpose: Trains SVM\n",
    "# Return: list of valid_errors from each experiment\n",
    "def train_svm_no_plot(samples, clf, train_set, train_y, valid_set, valid_y, name):\n",
    "    train_scores = list()\n",
    "    valid_scores = list()\n",
    "    for sample_size in samples:\n",
    "        clf.fit(train_set[:sample_size], train_y[:sample_size])\n",
    "        train_score = clf.score(train_set, train_y)\n",
    "        train_scores.append(train_score)\n",
    "        valid_score = clf.score(valid_set, valid_y)\n",
    "        valid_scores.append(valid_score)\n",
    "    return valid_scores, train_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> B. Training MNIST And Plotting Accuracies</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# *********************PROBLEM 2 --> TRAIN DATA ***********************\n",
    "\n",
    "# ----------TRAIN MNIST DATA------------#\n",
    "clf_mnist = SVC(kernel=\"linear\")\n",
    "experiments = [100, 200, 500, 1000, 2000, 5000, 10000]\n",
    "# expect between 70-90% accuracy\n",
    "valid_error, train_error = train_svm(experiments, clf_mnist, mnist_train_set, mnist_train_y, mnist_valid_set, mnist_valid_y,\n",
    "          'MNIST')\n",
    "print('ACCURACIES:')\n",
    "print('Valid_error is: ' + str(valid_error))\n",
    "print('__________________________________')\n",
    "print('Train_error is: ' + str(train_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "<h3> B. Training CIFAR And Plotting Accuracies</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -----------TRAIN CIFAR DATA-----------#\n",
    "print(\"Training CIFAR\")\n",
    "clf_cifar = SVC(kernel='linear')\n",
    "experiments = [100, 200, 500, 1000, 2000, 5000]\n",
    "# expect between 25-35% accuracy\n",
    "valid_error, train_error = train_svm(experiments, clf_cifar, cifar_train_set, cifar_train_y, cifar_valid_set, cifar_valid_y, 'CIFAR')\n",
    "print('ACCURACIES:')\n",
    "print('Valid_error is: ' + str(valid_error))\n",
    "print('__________________________________')\n",
    "print('Train_error is: ' + str(train_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "<h3> B. Training SPAM And Plotting Accuracies</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ----------TRAIN SPAM DATA -------------\n",
    "print(\"Training SPAM\")\n",
    "clf_spam = SVC(kernel=\"linear\")\n",
    "experiments = [100, 200, 500, 1000, 2000, 4137]\n",
    "# expect between 70-90% accuracy\n",
    "valid_error, train_error = train_svm(experiments, clf_spam, spam_train_set, spam_train_y, spam_valid_set, spam_valid_y, 'SPAM')\n",
    "print('ACCURACIES:')\n",
    "print('Valid_error is: ' + str(valid_error))\n",
    "print('__________________________________')\n",
    "print('Train_error is: ' + str(train_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 3: HYPERTUNING C-VALUE (REGULARIZATION PARAMETER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> A. TESTING SMALL VALUES OF C </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ************************** PROBLEM 3: BEST C Value ********************************\n",
    "from sklearn.svm import SVC\n",
    "C_range = [.01, .001, .0001, .00001, .000001, .0000001, .00000001, .000000001]\n",
    "experiments = [10000]\n",
    "print('TESTING C VALUES (REGULARIZATION PARAM)')\n",
    "for C in C_range:\n",
    "    clf_mnist = SVC(kernel=\"linear\", C=C)\n",
    "    scores = train_svm_no_plot(experiments, clf_mnist, mnist_train_set, mnist_train_y, mnist_valid_set, mnist_valid_y, 'MNIST')\n",
    "    print('C value: ' + str(C))\n",
    "    print('valid_score ' + str(scores[0]))\n",
    "    print('__________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> B. Modifying C Values Based On Observations from A. </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ************************** PROBLEM 3: BEST C Value ********************************\n",
    "from sklearn.svm import SVC\n",
    "C_range = [.000002, .000003, .000004, .000005, .000006]\n",
    "experiments = [10000]\n",
    "for C in C_range:\n",
    "    clf_mnist = SVC(kernel=\"linear\", C=C)\n",
    "    scores = train_svm_no_plot(experiments, clf_mnist, mnist_train_set, mnist_train_y, mnist_valid_set, mnist_valid_y, 'MNIST')\n",
    "    print('C value: ' + str(C))\n",
    "    print('valid_score ' + str(scores[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 4: K-FOLD CROSS EXAMINATION: FINDING BEST MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ************************** PROBLEM 4: K-FOLD ********************************\n",
    "def k_fold_split(data, clf, k, name):\n",
    "    np.random.shuffle(data)\n",
    "    valid_errors = list()\n",
    "    copy_data = data[:, :]\n",
    "    for i in range(k):\n",
    "        if is_divisible_by_k(copy_data, k):\n",
    "            k_arrays = np.split(copy_data, k)\n",
    "        else:\n",
    "            divisible_data, extra_data = preprocess_data(copy_data, k)\n",
    "            k_arrays = np.split(divisible_data, k)\n",
    "            np.vstack((k_arrays[-1], extra_data)) \n",
    "        valid_set = k_arrays.pop(i)\n",
    "        valid_data = valid_set[:, :-1]\n",
    "        valid_y = valid_set[:, -1]\n",
    "        train_set = np.vstack(k_arrays)\n",
    "        train_data = train_set[:, :-1]\n",
    "        train_y = train_set[:, -1]\n",
    "        valid_errors.append(train_svm_no_plot([train_data.shape[0]], clf, train_data, train_y, valid_data, valid_y, name)[0])\n",
    "    valid_score = np.sum(valid_errors)/k\n",
    "    print(\"Valid Score is:\")\n",
    "    print(valid_score)\n",
    "    return valid_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_data(data, k):\n",
    "    remainder = data.shape[0] % k\n",
    "    extra_samples = data[-remainder:, :]\n",
    "    divisible_samples = data[:-remainder, :]\n",
    "    return divisible_samples, extra_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_divisible_by_k(data, k):\n",
    "    if data.shape[0] % k == 0:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running KFOLD\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'SVC' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-339fcf652a6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Running KFOLD\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclf_spam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# both arrays need to be 2-dimensional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtwo_dim_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mspam_train_y\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtransposed_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtwo_dim_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SVC' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Running KFOLD\")\n",
    "clf_spam = SVC(C = 0.01)\n",
    "# both arrays need to be 2-dimensional\n",
    "two_dim_label = np.array([spam_train_y])\n",
    "transposed_labels = two_dim_label.T\n",
    "print('training set data: ' + str(spam_train_set.shape))\n",
    "print('transposed_labels ' + str(transposed_labels.shape))\n",
    "spam_training = np.hstack((spam_train_set, transposed_labels))\n",
    "print('spam_concatenated: ' + str(spam_training.shape))\n",
    "k_fold_split(spam_training, clf_spam, 5, 'SPAM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# STEP 6: REFLECTION AND SUMMARY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [189hw]",
   "language": "python",
   "name": "Python [189hw]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
